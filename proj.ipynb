{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import marimo as mo\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import py_vollib.black.implied_volatility as pyv_iv\n",
    "from py_vollib.helpers import forward_price as pv_forward_price\n",
    "\n",
    "pd.options.display.width = 140\n",
    "pd.options.display.max_columns = 20\n",
    "\n",
    "PROJECT_ROOT = Path(\".\")\n",
    "SESSION_FOLDERS = {\"ETH\": PROJECT_ROOT / \"ETH\", \"RTH\": PROJECT_ROOT / \"RTH\"}\n",
    "RISK_FREE_RATE = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Cleaning ETH and RTH Market Data\n",
    "We combine extended trading hours (ETH) and regular trading hours (RTH) datasets into tidy\n",
    "assets and option dataframes ready for downstream analysis.\n",
    "## Dataset Overview\n",
    "- **RTH vs ETH**: RTH covers the standard 09:30â€“16:00 ET NYSE session while ETH captures overnight and\n",
    "  pre/post-market activity. Comparing both windows is vital because volatility shocks can start or fade outside\n",
    "  cash hours, yet still influence pricing when the market reopens.\n",
    "- **SPX**: The S&P 500 index represents the underlying spot level for every SPX option we analyze; tracking it\n",
    "  alongside option quotes lets us compute moneyness, spot returns, and link surface shifts to index swings.\n",
    "- **VIX**: The CBOE Volatility Index summarizes the 30-day implied variance from listed options, so monitoring\n",
    "  it provides a benchmark for whether our bespoke volatility surfaces are consistent with market sentiment.\n",
    "- **ES futures**: Front-month E-mini S&P 500 futures trade nearly 24 hours, offering a tradable proxy for SPX\n",
    "  during ETH. Their bid/ask levels reveal how much of a move occurs before the cash market opens and aid in\n",
    "  aligning option timestamps with corresponding underlying prices.\n",
    "- **SPX options**: These listed index options across strikes/expiries supply the bid/ask quotes feeding our\n",
    "  implied-volatility surface, risk-neutral PDF extraction, and hedging analysis; clean quotes are essential for\n",
    "  reliable Greeks and surface diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Imports and Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "# Helper routines: parsing CSVs, melting option quotes, and orchestrating session-level loads.\n",
    "def parse_timestamped_csv(csv_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load a CSV whose first column stores timestamps and return a tidy timestamp column.\"\"\"\n",
    "    frame = pd.read_csv(csv_path, index_col=0)\n",
    "    frame.index = pd.to_datetime(frame.index)\n",
    "    frame = frame.reset_index().rename(columns={\"index\": \"timestamp\"})\n",
    "    return frame\n",
    "\n",
    "def melt_option_quotes(frame: pd.DataFrame, value_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Convert wide strike columns into long format for a single quote side.\"\"\"\n",
    "    melted = frame.melt(\n",
    "        id_vars=\"timestamp\", var_name=\"strike\", value_name=value_name\n",
    "    )\n",
    "    melted[\"strike\"] = pd.to_numeric(melted[\"strike\"], errors=\"coerce\")\n",
    "    melted[value_name] = pd.to_numeric(melted[value_name], errors=\"coerce\")\n",
    "    return melted\n",
    "\n",
    "def load_option_book(assets: pd.DataFrame | None = None) -> pd.DataFrame:\n",
    "    \"\"\"Load and merge bid/ask quotes for calls and puts acrjkjkjkjkjkjkjkjkjkjkjkjkoss sessions.\"\"\"\n",
    "    if assets is None:\n",
    "        assets = load_assets()\n",
    "\n",
    "    records: list[pd.DataFrame] = []\n",
    "    for option_type in (\"call\", \"put\"):\n",
    "        for session, folder in SESSION_FOLDERS.items():\n",
    "            ask_files = sorted(folder.glob(f\"*_{option_type}_ask_*.csv\"))\n",
    "            for ask_path in ask_files:\n",
    "                stem_parts = ask_path.stem.split(\"_\")\n",
    "                expiry = pd.to_datetime(stem_parts[-1])\n",
    "                bid_path = ask_path.with_name(\n",
    "                    ask_path.name.replace(\"_ask_\", \"_bid_\")\n",
    "                )\n",
    "\n",
    "                # Convert the wide strike grid into tidy bid/ask quote tables.\n",
    "                ask_frame = melt_option_quotes(\n",
    "                    parse_timestamped_csv(ask_path), \"ask\"\n",
    "                )\n",
    "                bid_frame = melt_option_quotes(\n",
    "                    parse_timestamped_csv(bid_path), \"bid\"\n",
    "                )\n",
    "                merged = pd.merge(\n",
    "                    ask_frame, bid_frame, on=[\"timestamp\", \"strike\"], how=\"outer\"\n",
    "                )\n",
    "\n",
    "                # Replace placeholder -1 quotes with NaN and remove empty markets.\n",
    "                merged[[\"bid\", \"ask\"]] = merged[[\"bid\", \"ask\"]].replace(-1, np.nan)\n",
    "                merged = merged.dropna(subset=[\"bid\", \"ask\"])\n",
    "\n",
    "                # Attach contract metadata and maturity measures.\n",
    "                merged[\"expiry\"] = expiry\n",
    "                merged[\"session\"] = session\n",
    "                merged[\"option_type\"] = option_type\n",
    "\n",
    "                time_delta_days = (\n",
    "                    merged[\"expiry\"] - merged[\"timestamp\"]\n",
    "                ).dt.total_seconds() / 86400\n",
    "                merged[\"time_to_maturity_days\"] = time_delta_days.round().astype(\n",
    "                    \"Int64\"\n",
    "                )\n",
    "                merged[\"time_to_maturity_years\"] = time_delta_days / 365.25\n",
    "\n",
    "                # Use the midpoint as the transactable option value.\n",
    "                merged[\"option_price\"] = merged[[\"bid\", \"ask\"]].mean(axis=1)\n",
    "\n",
    "                records.append(merged)\n",
    "\n",
    "    # Combine all sessions/files into one chronologically ordered long DataFrame.\n",
    "    long_df = pd.concat(records, ignore_index=True)\n",
    "\n",
    "    # Prepare the SPX snapshot and forward proxy to align with option quotes.\n",
    "    asset_slice = assets[[\"timestamp\", \"session\", \"SPX\", \"ES_BID\", \"ES_ASK\"]].copy()\n",
    "    asset_slice[\"forward_price\"] = asset_slice[[\"ES_BID\", \"ES_ASK\"]].mean(axis=1)\n",
    "    asset_slice = asset_slice.drop(columns=[\"ES_BID\", \"ES_ASK\"])\n",
    "\n",
    "    # Merge the nearest prior asset snapshot within each session onto every option row.\n",
    "    long_df[\"session\"] = long_df[\"session\"].astype(\"category\")\n",
    "    asset_slice[\"session\"] = asset_slice[\"session\"].astype(\"category\")\n",
    "\n",
    "    # Sort cols before we can use merge_asof\n",
    "    long_df = long_df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    asset_slice = asset_slice.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "    long_df = pd.merge_asof(\n",
    "        long_df,\n",
    "        asset_slice,\n",
    "        on=\"timestamp\",\n",
    "        by=\"session\",\n",
    "        direction=\"backward\",\n",
    "        allow_exact_matches=True,\n",
    "    )\n",
    "\n",
    "    # Mark the strike(s) closest to the forward price as ATM per timestamp/expiry/session.\n",
    "    long_df[\"is_atm\"] = False\n",
    "    atm_mask = (\n",
    "        long_df[\"forward_price\"].notna()\n",
    "        & long_df[\"strike\"].notna()\n",
    "        & long_df[\"timestamp\"].notna()\n",
    "        & long_df[\"expiry\"].notna()\n",
    "    )\n",
    "    if atm_mask.any():\n",
    "        subset = long_df.loc[\n",
    "            atm_mask, [\"timestamp\", \"expiry\", \"session\", \"strike\", \"forward_price\"]\n",
    "        ].copy()\n",
    "        subset[\"distance\"] = (subset[\"strike\"] - subset[\"forward_price\"]).abs()\n",
    "        min_distance = subset.groupby([\"timestamp\", \"expiry\", \"session\"])[\n",
    "            \"distance\"\n",
    "        ].transform(\"min\")\n",
    "        long_df.loc[subset.index, \"is_atm\"] = subset[\"distance\"].eq(min_distance)\n",
    "\n",
    "    # Flag out-of-the-money contracts relative to the forward.\n",
    "    long_df[\"is_otm\"] = (\n",
    "        (long_df[\"option_type\"] == \"call\")\n",
    "        & (long_df[\"strike\"] > long_df[\"forward_price\"])\n",
    "    ) | (\n",
    "        (long_df[\"option_type\"] == \"put\")\n",
    "        & (long_df[\"strike\"] < long_df[\"forward_price\"])\n",
    "    )\n",
    "\n",
    "    # Compute py_vollib-consistent intrinsic values using discounted forward payoffs.\n",
    "    long_df = long_df.dropna(\n",
    "        subset=[\"option_price\", \"SPX\", \"strike\", \"time_to_maturity_years\"]\n",
    "    )\n",
    "    bs_forward = pv_forward_price(\n",
    "        long_df[\"SPX\"], long_df[\"time_to_maturity_years\"], RISK_FREE_RATE\n",
    "    )\n",
    "    undiscounted_intrinsic = np.where(\n",
    "        long_df[\"option_type\"] == \"call\",\n",
    "        np.maximum(bs_forward - long_df[\"strike\"], 0.0),\n",
    "        np.maximum(long_df[\"strike\"] - bs_forward, 0.0),\n",
    "    )\n",
    "    discount_factor = np.exp(-RISK_FREE_RATE * long_df[\"time_to_maturity_years\"])\n",
    "    long_df[\"intrinsic_value\"] = undiscounted_intrinsic * discount_factor\n",
    "\n",
    "    # Enforce strictly positive time value to avoid numerical issues with IV solvers.\n",
    "    time_value = long_df[\"option_price\"] - long_df[\"intrinsic_value\"]\n",
    "    time_value_tol = 1e-6\n",
    "    long_df = long_df[time_value > time_value_tol].copy()\n",
    "\n",
    "    return long_df\n",
    "\n",
    "def load_assets() -> pd.DataFrame:\n",
    "    \"\"\"Load SPX/ES/VIX snapshots from both sessions.\"\"\"\n",
    "    frames: list[pd.DataFrame] = []\n",
    "    for session, folder in SESSION_FOLDERS.items():\n",
    "        for csv_path in sorted(folder.glob(\"*_assets.csv\")):\n",
    "            frame = parse_timestamped_csv(csv_path)\n",
    "            frame[\"session\"] = session\n",
    "            frames.append(frame)\n",
    "\n",
    "    assets = pd.concat(frames, ignore_index=True)\n",
    "    assets = assets.astype(\n",
    "        {\n",
    "            \"SPX\": \"Float64\",\n",
    "            \"ES_BID\": \"Float64\",\n",
    "            \"ES_ASK\": \"Float64\",\n",
    "            \"VIX\": \"Float64\",\n",
    "            \"session\": \"category\",\n",
    "        }\n",
    "    )\n",
    "    assets = assets.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    return assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKri",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Visualization Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "# Provide reusable plotting helpers for exploratory analysis.\n",
    "SESSION_COLORS = {\"RTH\": \"#2ca02c\", \"ETH\": \"#1f77b4\"}\n",
    "\n",
    "def _shade_session_blocks(ax, series: pd.DataFrame) -> None:\n",
    "    \"\"\"Overlay lightly shaded regions for ETH and RTH stretches.\"\"\"\n",
    "    legend_labels = set()\n",
    "    session_switch = series[\"session\"].ne(series[\"session\"].shift()).cumsum()\n",
    "    for _, block in series.groupby(session_switch):\n",
    "        session_name = block[\"session\"].iloc[0]\n",
    "        color = SESSION_COLORS.get(session_name, \"gray\")\n",
    "        ax.axvspan(\n",
    "            block[\"timestamp\"].iloc[0],\n",
    "            block[\"timestamp\"].iloc[-1],\n",
    "            color=color,\n",
    "            alpha=0.08,\n",
    "            label=session_name if session_name not in legend_labels else None,\n",
    "        )\n",
    "        legend_labels.add(session_name)\n",
    "\n",
    "def _shade_weekends(ax, series: pd.DataFrame) -> None:\n",
    "    \"\"\"Shade weekend periods to highlight market closures.\"\"\"\n",
    "    if series.empty:\n",
    "        return\n",
    "    start = series[\"timestamp\"].min().normalize()\n",
    "    end = series[\"timestamp\"].max().normalize()\n",
    "    dates = pd.date_range(start, end, freq=\"D\")\n",
    "    weekend_label_added = False\n",
    "    for day in dates:\n",
    "        if day.dayofweek == 5:  # Saturday marks the start of the weekend\n",
    "            ax.axvspan(\n",
    "                day,\n",
    "                day + pd.Timedelta(days=2),\n",
    "                color=\"gray\",\n",
    "                alpha=0.12,\n",
    "                label=\"Weekend\" if not weekend_label_added else None,\n",
    "            )\n",
    "            weekend_label_added = True\n",
    "\n",
    "def plot_timeseries(\n",
    "    data: pd.DataFrame,\n",
    "    column: str,\n",
    "    label: str,\n",
    "    session: str | None = None,\n",
    "    line_color: str = \"black\",\n",
    ") -> None:\n",
    "    \"\"\"Display a single time series with ETH/RTH overlays and weekend cues.\"\"\"\n",
    "    subset = data.copy()\n",
    "    if session is not None:\n",
    "        subset = subset[subset[\"session\"] == session]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax.plot(\n",
    "        subset[\"timestamp\"],\n",
    "        subset[column],\n",
    "        color=line_color,\n",
    "        linewidth=1.5,\n",
    "        label=label,\n",
    "    )\n",
    "\n",
    "    _shade_session_blocks(ax, subset)\n",
    "    _shade_weekends(ax, subset)\n",
    "\n",
    "    ax.set_ylabel(label)\n",
    "    ax.set_xlabel(\"Timestamp\")\n",
    "    ax.set_title(f\"{label} Over Time\" + (f\" - {session}\" if session else \"\"))\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    event_date = pd.Timestamp(\"2025-04-02 16:00:00\")\n",
    "    ax.axvline(\n",
    "        event_date,\n",
    "        color=\"red\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=2,\n",
    "        label=\"Liberation Day Tariffs (2 Apr 2025)\",\n",
    "    )\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels, loc=\"best\")\n",
    "    fig.autofmt_xdate()\n",
    "    plt.tight_layout()\n",
    "\n",
    "def plot_vol_smiles_by_period(\n",
    "    options: pd.DataFrame,\n",
    "    period: str,\n",
    "    *,\n",
    "    event_day: pd.Timestamp = pd.Timestamp(\"2025-04-02 16:00:00\"),\n",
    "    maturity_col: str = \"time_to_maturity_days\",\n",
    "    forward_col: str = \"forward_price\",\n",
    "    strike_col: str = \"strike\",\n",
    "    iv_col: str = \"implied_vol\",\n",
    "    min_quotes: int = 5,\n",
    ") -> None:\n",
    "    \"\"\"Plot volatility smiles (IV vs log-moneyness) for each maturity bucket within a given event period.\"\"\"\n",
    "    if options.empty:\n",
    "        raise ValueError(\"No option data provided for plotting.\")\n",
    "\n",
    "    timestamps = options[\"timestamp\"]\n",
    "\n",
    "    # 1) Select the event window: before / during / after.\n",
    "    event_ts = event_day\n",
    "    # End of the event day = midnight of the *next* day\n",
    "    event_day_end = event_ts.normalize() + pd.Timedelta(days=1)\n",
    "\n",
    "    period_lower = period.lower()\n",
    "    if period_lower == \"before\":\n",
    "        mask = timestamps < event_ts\n",
    "        title_fragment = \"Before Liberation Day\"\n",
    "    elif period_lower == \"during\":\n",
    "        mask = (timestamps >= event_ts) & (timestamps < event_day_end)\n",
    "        title_fragment = \"During Liberation Day\"\n",
    "    elif period_lower == \"after\":\n",
    "        mask = timestamps >= event_day_end\n",
    "        title_fragment = \"After Liberation Day\"\n",
    "    else:\n",
    "        raise ValueError(\"period must be one of {'before', 'during', 'after'}\")\n",
    "\n",
    "    # 2) Filter to the chosen period and drop unusable rows.\n",
    "    subset = (\n",
    "        options.loc[mask]\n",
    "        .dropna(subset=[forward_col, strike_col, iv_col, maturity_col])\n",
    "        .copy()\n",
    "    )\n",
    "    if subset.empty:\n",
    "        raise ValueError(f\"No quotes available for period '{period}'.\")\n",
    "\n",
    "    # Require positive forward and strike for log(K/F).\n",
    "    subset = subset[(subset[forward_col] > 0) & (subset[strike_col] > 0)].copy()\n",
    "    if subset.empty:\n",
    "        raise ValueError(\n",
    "            f\"No valid quotes with positive {forward_col} and {strike_col} for period '{period}'.\"\n",
    "        )\n",
    "\n",
    "    # 3) Compute log-moneyness: k = ln(K / F).\n",
    "    subset[\"log_moneyness\"] = np.log(subset[strike_col] / subset[forward_col])\n",
    "\n",
    "    # 4) Bucket by maturity (days).\n",
    "    subset[maturity_col] = subset[maturity_col].astype(int)\n",
    "    ordered_maturities = sorted(subset[maturity_col].unique())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(ordered_maturities)))\n",
    "\n",
    "    # 5) Plot IV vs log-moneyness for each maturity.\n",
    "    plotted_any = False\n",
    "    for color, maturity in zip(colors, ordered_maturities):\n",
    "        maturity_slice = subset[subset[maturity_col] == maturity]\n",
    "        maturity_slice = maturity_slice.sort_values(\"log_moneyness\")\n",
    "        if len(maturity_slice) < min_quotes:\n",
    "            continue\n",
    "\n",
    "        ax.plot(\n",
    "            maturity_slice[\"log_moneyness\"],\n",
    "            maturity_slice[iv_col],\n",
    "            label=f\"{maturity}d\",\n",
    "            color=color,\n",
    "            linewidth=1.5,\n",
    "        )\n",
    "        plotted_any = True\n",
    "\n",
    "    if not plotted_any:\n",
    "        raise ValueError(f\"Not enough quotes to plot smiles for period '{period}'.\")\n",
    "\n",
    "    ax.set_title(f\"Volatility Smiles {title_fragment}\")\n",
    "    ax.set_xlabel(\"Log-moneyness  ln(K / F)\")\n",
    "    ax.set_ylabel(\"Implied Volatility\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    ax.legend(title=\"TTM (days)\", loc=\"best\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Start\n",
    "## Load Assets Across Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, clean, and combine SPX, ES, and VIX snapshots from ETH and RTH.\n",
    "assets_df = load_assets()\n",
    "assets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SPX over time.\n",
    "plot_timeseries(assets_df, column=\"SPX\", label=\"SPX\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize VIX over time.\n",
    "plot_timeseries(assets_df, column=\"VIX\", label=\"VIX\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hstk",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Load Option Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the consolidated option dataframe with bid/ask/mid quotes.\n",
    "options_df = load_option_book(assets_df)\n",
    "options_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iLit",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Filter ATM/OTM Options via Forward and Compute IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forward price from load_option_book to identify ATM/OTM quotes and compute IVs.\n",
    "valid_quotes = options_df.dropna(\n",
    "    subset=[\"forward_price\", \"option_price\", \"strike\", \"time_to_maturity_years\"]\n",
    ")\n",
    "valid_quotes = valid_quotes[valid_quotes[\"time_to_maturity_years\"] > 0].copy()\n",
    "\n",
    "atm_otm_options = valid_quotes[\n",
    "    valid_quotes[\"is_atm\"] | valid_quotes[\"is_otm\"]\n",
    "].copy()\n",
    "\n",
    "def _compute_implied_vol(row: pd.Series) -> float:\n",
    "    flag = \"c\" if row[\"option_type\"] == \"call\" else \"p\"\n",
    "    return pyv_iv.implied_volatility(\n",
    "        row[\"option_price\"],\n",
    "        row[\"forward_price\"],\n",
    "        row[\"strike\"],\n",
    "        row[\"time_to_maturity_years\"],\n",
    "        RISK_FREE_RATE,\n",
    "        flag,\n",
    "    )\n",
    "\n",
    "atm_otm_options[\"implied_vol\"] = atm_otm_options.apply(_compute_implied_vol, axis=1)\n",
    "atm_otm_options.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 15-day volatility smiles for the three event windows.\n",
    "subset = atm_otm_options.dropna(\n",
    "    subset=[\"time_to_maturity_days\", \"implied_vol\", \"strike\", \"timestamp\"]\n",
    ").copy()\n",
    "subset[\"time_to_maturity_days\"] = (\n",
    "    subset[\"time_to_maturity_days\"].round().astype(int)\n",
    ")\n",
    "\n",
    "for period in (\"before\", \"during\", \"after\"):\n",
    "    plot_vol_smiles_by_period(subset, period, min_quotes=3)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
